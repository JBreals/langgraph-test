# PTE Agent ë¹„ë™ê¸° ì „í™˜ ê³„íš

## ê°œìš”

í˜„ì¬ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹(ì´ë²¤íŠ¸ ë£¨í”„ + ThreadPoolExecutor)ì—ì„œ ì™„ì „ ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì „í™˜í•˜ê¸° ìœ„í•œ ì„¸ë¶€ ê³„íš.

### ì „í™˜ ëª©í‘œ
- ëª¨ë“  I/O ì‘ì—…ì„ ë‹¨ì¼ ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ì²˜ë¦¬
- `run_in_executor` ì œê±°
- ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ë° ë™ì‹œì„± ê°œì„ 

### ì „ì œ ì¡°ê±´
- Python 3.11+
- LangChain/LangGraph async ì§€ì› (`ainvoke`, `astream`)
- Tavily `AsyncTavilyClient` ì§€ì› í™•ì¸ë¨
- httpx `AsyncClient` ì‚¬ìš©

---

## íŒŒì¼ë³„ ë³€í™˜ ê³„íš

### 1. Tools Layer

#### `src/tools/web_search.py`
**ë‚œì´ë„**: ì‰¬ì›€

```python
# Before
from tavily import TavilyClient

def web_search(...) -> str:
    client = TavilyClient(api_key=settings.tavily_api_key)
    response = client.search(...)
    return result

def _extract_webpages(client, urls: list[str]) -> str:
    response = client.extract(urls=urls)
    return content

# After
from tavily import AsyncTavilyClient

async def web_search(...) -> str:
    client = AsyncTavilyClient(api_key=settings.tavily_api_key)
    response = await client.search(...)
    return result

async def _extract_webpages(client: AsyncTavilyClient, urls: list[str]) -> str:
    response = await client.extract(urls=urls)
    return content
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] `TavilyClient` â†’ `AsyncTavilyClient`
- [ ] `client.search()` â†’ `await client.search()`
- [ ] `client.extract()` â†’ `await client.extract()`
- [ ] í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ `def` â†’ `async def`

---

#### `src/tools/rag_retrieve.py`
**ë‚œì´ë„**: ì‰¬ì›€

```python
# Before
import httpx

def _get_embedding(text: str) -> list[float] | None:
    with httpx.Client() as client:
        response = client.post(...)
    return embedding

def rag_retrieve(...) -> str:
    embedding = _get_embedding(query)
    # Pinecone í˜¸ì¶œ
    return results

# After
import httpx

async def _get_embedding(text: str) -> list[float] | None:
    async with httpx.AsyncClient() as client:
        response = await client.post(...)
    return embedding

async def rag_retrieve(...) -> str:
    embedding = await _get_embedding(query)
    # Pinecone async í˜¸ì¶œ (pinecone-client 3.x ì§€ì›)
    return results
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] `httpx.Client` â†’ `httpx.AsyncClient`
- [ ] `client.post()` â†’ `await client.post()`
- [ ] Pinecone async ì§€ì› í™•ì¸ (`index.query()` â†’ `await index.query()`)
- [ ] ìºì‹œ í†µí•© ì‹œ async í˜¸í™˜ì„± í™•ì¸

---

#### `src/tools/query_enhancer.py`
**ë‚œì´ë„**: ì‰¬ì›€

```python
# Before
def enhance_query(...) -> str:
    response = llm.invoke([...])
    return enhanced_query

# After
async def enhance_query(...) -> str:
    response = await llm.ainvoke([...])
    return enhanced_query
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] `llm.invoke()` â†’ `await llm.ainvoke()`
- [ ] í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½

---

### 2. Nodes Layer

ëª¨ë“  ë…¸ë“œ íŒŒì¼ì— ë™ì¼í•œ íŒ¨í„´ ì ìš©.

#### `src/pte/nodes/intent_classifier.py`
```python
# Before
def intent_classifier_node(state: PTEState) -> dict:
    response = llm.invoke([...])
    return {...}

# After
async def intent_classifier_node(state: PTEState) -> dict:
    response = await llm.ainvoke([...])
    return {...}
```

#### `src/pte/nodes/planner.py`
```python
# Before
def planner_node(state: PTEState) -> dict:
    response = llm.invoke([...])
    return {...}

# After
async def planner_node(state: PTEState) -> dict:
    response = await llm.ainvoke([...])
    return {...}
```

#### `src/pte/nodes/executor.py`
```python
# Before
def executor_node(state: PTEState) -> dict:
    # tool í˜¸ì¶œ
    result = tool_func(...)
    return {...}

# After
async def executor_node(state: PTEState) -> dict:
    # async tool í˜¸ì¶œ
    result = await tool_func(...)
    return {...}
```

**ì£¼ì˜**: executorì—ì„œ í˜¸ì¶œí•˜ëŠ” ëª¨ë“  toolì´ asyncì—¬ì•¼ í•¨.

#### `src/pte/nodes/replanner.py`
```python
async def replanner_node(state: PTEState) -> dict:
    response = await llm.ainvoke([...])
    return {...}
```

#### `src/pte/nodes/final_answer.py`
```python
async def final_answer_node(state: PTEState) -> dict:
    response = await llm.ainvoke([...])
    return {"result": response.content}
```

**ë…¸ë“œ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] `intent_classifier.py` - `ainvoke` ì ìš©
- [ ] `planner.py` - `ainvoke` ì ìš©
- [ ] `executor.py` - async tool í˜¸ì¶œ
- [ ] `replanner.py` - `ainvoke` ì ìš©
- [ ] `final_answer.py` - `ainvoke` ì ìš©

---

### 3. Graph Layer

#### `src/pte/graph.py`
**ë‚œì´ë„**: ì¤‘ê°„

```python
# Before
from langgraph.graph import StateGraph

def get_pte_graph():
    graph = StateGraph(PTEState)
    graph.add_node("intent_classifier", intent_classifier_node)
    graph.add_node("planner", planner_node)
    # ...
    return graph.compile()

# After
from langgraph.graph import StateGraph

def get_pte_graph():
    graph = StateGraph(PTEState)
    # async ë…¸ë“œ ë“±ë¡ (LangGraphê°€ ìë™ ê°ì§€)
    graph.add_node("intent_classifier", intent_classifier_node)  # async def
    graph.add_node("planner", planner_node)  # async def
    # ...
    return graph.compile()
```

**ì°¸ê³ **: LangGraphëŠ” async ë…¸ë“œë¥¼ ìë™ ê°ì§€í•˜ì—¬ ì²˜ë¦¬í•¨. ë…¸ë“œ ë“±ë¡ ì½”ë“œëŠ” ë³€ê²½ ë¶ˆí•„ìš”.

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ëª¨ë“  ë…¸ë“œê°€ asyncì¸ì§€ í™•ì¸
- [ ] ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ê°€ async í•„ìš”í•œì§€ í™•ì¸

---

### 4. API Layer

#### `src/api/routes/chat.py`
**ë‚œì´ë„**: ì¤‘ê°„

```python
# Before (í•˜ì´ë¸Œë¦¬ë“œ)
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=4)

@router.post("/chat")
async def chat(request: ChatRequest):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        executor,
        graph.invoke,
        initial_state
    )
    return {"response": result["result"]}

# After (ìˆœìˆ˜ async)
@router.post("/chat")
async def chat(request: ChatRequest):
    result = await graph.ainvoke(initial_state)
    return {"response": result["result"]}
```

#### ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
```python
# Before
@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def generate():
        loop = asyncio.get_event_loop()
        # ë™ê¸° streamì„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        for event in await loop.run_in_executor(executor, list, graph.stream(state)):
            yield f"data: {json.dumps(event)}\n\n"
    return StreamingResponse(generate(), media_type="text/event-stream")

# After
@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def generate():
        async for event in graph.astream(initial_state):
            yield f"data: {json.dumps(event)}\n\n"
    return StreamingResponse(generate(), media_type="text/event-stream")
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] `ThreadPoolExecutor` ì œê±°
- [ ] `run_in_executor` ì œê±°
- [ ] `graph.invoke()` â†’ `await graph.ainvoke()`
- [ ] `graph.stream()` â†’ `async for ... in graph.astream()`

---

### 5. Entry Point

#### `main.py` (CLI)
**ë‚œì´ë„**: ì‰¬ì›€

```python
# Before
def run_agent(...) -> tuple[str, str | None]:
    graph = get_pte_graph()
    final_state = graph.invoke(initial_state)
    return result, rewritten

def main():
    while True:
        result, rewritten = run_agent(user_input, history)
        print(f"Agent: {result}")

# After
import asyncio

async def run_agent(...) -> tuple[str, str | None]:
    graph = get_pte_graph()
    final_state = await graph.ainvoke(initial_state)
    return result, rewritten

async def main():
    while True:
        result, rewritten = await run_agent(user_input, history)
        print(f"Agent: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

**ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ**:
```python
async def run_agent_stream(...):
    graph = get_pte_graph()
    async for event in graph.astream(initial_state):
        for node_name, node_output in event.items():
            print(f"ğŸ“ Node: {node_name}")
            # ...
```

---

## ì˜ì¡´ì„± ì—…ë°ì´íŠ¸

### `requirements.txt` ë˜ëŠ” `pyproject.toml`

```txt
# ê¸°ì¡´
tavily-python>=0.3.0
httpx>=0.25.0
langchain>=0.1.0
langgraph>=0.0.20

# í™•ì¸ í•„ìš”
pinecone-client>=3.0.0  # async ì§€ì› ë²„ì „
```

### Pinecone Async ì§€ì›

Pinecone Python SDK 3.xë¶€í„° async ì§€ì›:
```python
from pinecone import Pinecone

pc = Pinecone(api_key="...")
index = pc.Index("index-name")

# Async query
results = await index.query(vector=[...], top_k=5)
```

---

## ì „í™˜ ìˆœì„œ (ê¶Œì¥)

### Phase 1: Tools Layer
1. `query_enhancer.py` - ê°€ì¥ ë‹¨ìˆœ
2. `rag_retrieve.py` - httpx async
3. `web_search.py` - Tavily async

### Phase 2: Nodes Layer
4. `intent_classifier.py`
5. `planner.py`
6. `replanner.py`
7. `final_answer.py`
8. `executor.py` - tools ì˜ì¡´

### Phase 3: Graph & API
9. `graph.py` - ë…¸ë“œ í†µí•© í™•ì¸
10. `routes/chat.py` - API ì „í™˜
11. `main.py` - CLI ì „í™˜

### Phase 4: ì •ë¦¬
12. `ThreadPoolExecutor` ê´€ë ¨ ì½”ë“œ ì œê±°
13. ë¶ˆí•„ìš”í•œ sync wrapper ì œê±°
14. í…ŒìŠ¤íŠ¸ ì½”ë“œ async ì „í™˜

---

## í…ŒìŠ¤íŠ¸ ì „ëµ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
import pytest

@pytest.mark.asyncio
async def test_web_search():
    result = await web_search("test query", time_sensitive="none")
    assert result is not None

@pytest.mark.asyncio
async def test_intent_classifier():
    state = {...}
    result = await intent_classifier_node(state)
    assert "intent" in result
```

### í†µí•© í…ŒìŠ¤íŠ¸
```python
@pytest.mark.asyncio
async def test_full_graph():
    graph = get_pte_graph()
    result = await graph.ainvoke(initial_state)
    assert result["result"] is not None
```

### pytest ì„¤ì •
```toml
# pyproject.toml
[tool.pytest.ini_options]
asyncio_mode = "auto"
```

---

## ë¡¤ë°± ê³„íš

ë¬¸ì œ ë°œìƒ ì‹œ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ë¡¤ë°±:

1. ë…¸ë“œë¥¼ syncë¡œ ìœ ì§€
2. `run_in_executor`ë¡œ ê°ì‹¸ì„œ í˜¸ì¶œ
3. ì ì§„ì ìœ¼ë¡œ async ì „í™˜ ì¬ì‹œë„

```python
# ë¡¤ë°± íŒ¨í„´
async def chat(request: ChatRequest):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        executor,
        graph.invoke,  # sync ìœ ì§€
        initial_state
    )
    return {"response": result["result"]}
```

---

## ì˜ˆìƒ ì‘ì—…ëŸ‰

| ì˜ì—­ | íŒŒì¼ ìˆ˜ | ì˜ˆìƒ ë‚œì´ë„ |
|------|--------|------------|
| Tools | 3 | ì‰¬ì›€ |
| Nodes | 5 | ì‰¬ì›€ |
| Graph | 1 | ì¤‘ê°„ |
| API | 2 | ì¤‘ê°„ |
| CLI | 1 | ì‰¬ì›€ |
| Tests | ë‹¤ìˆ˜ | ì¤‘ê°„ |

**ì´ ì˜ˆìƒ**: í•µì‹¬ ì „í™˜ ~12ê°œ íŒŒì¼

---

## ì°¸ê³  ìë£Œ

- [LangGraph Async Documentation](https://langchain-ai.github.io/langgraph/)
- [Tavily Python SDK](https://docs.tavily.com/docs/python-sdk/tavily-search/getting-started)
- [httpx Async Client](https://www.python-httpx.org/async/)
- [Pinecone Python SDK v3](https://docs.pinecone.io/docs/python-client)
